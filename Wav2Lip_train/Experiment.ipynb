{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型训练\n",
    "模型的训练主要分为两个部分：\n",
    "1. Lip-Sync Expert Discriminator的训练。这里提供官方的预训练模型 [weight](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EQRvmiZg-HRAjvI6zqN9eTEBP74KefynCwPWVmF57l-AYA?e=ZRPHKP)\n",
    "2. Wav2Lip 模型的训练。\n",
    "\n",
    "### 3.1 预训练Lip-Sync Expert\n",
    "#### 1. 网络的搭建 \n",
    "上面我们已经介绍了SyncNet的基本网络结构，主要有一系列的(Conv+BatchNorm+Relu)组成，这里我们对其进行了一些改进，加入了残差结构。为了方便之后的使用，我们对(Conv+BatchNorm+Relu)以及残差模块进行了封装。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are models from Wav2lip project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, cin, cout, kernel_size, stride, padding, residual=False, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv_block = nn.Sequential(\n",
    "                            nn.Conv2d(cin, cout, kernel_size, stride, padding),\n",
    "                            nn.BatchNorm2d(cout)\n",
    "                            )\n",
    "        self.act = nn.ReLU()\n",
    "        self.residual = residual\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_block(x)\n",
    "        if self.residual:\n",
    "            out += x\n",
    "        return self.act(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nonorm_Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nonorm_Conv2d(nn.Module):\n",
    "    def __init__(self, cin, cout, kernel_size, stride, padding, residual=False, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv_block = nn.Sequential(\n",
    "                            nn.Conv2d(cin, cout, kernel_size, stride, padding),\n",
    "                            )\n",
    "        self.act = nn.LeakyReLU(0.01, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_block(x)\n",
    "        return self.act(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2dTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dTranspose(nn.Module):\n",
    "    def __init__(self, cin, cout, kernel_size, stride, padding, output_padding=0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv_block = nn.Sequential(\n",
    "                            nn.ConvTranspose2d(cin, cout, kernel_size, stride, padding, output_padding),\n",
    "                            nn.BatchNorm2d(cout)\n",
    "                            )\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_block(x)\n",
    "        return self.act(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SyncNet from Wav2Lip project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyncNet_color(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SyncNet_color, self).__init__()\n",
    "        \n",
    "        ################TODO###################\n",
    "        #根据上面提供的网络结构图，补全下面卷积网络的参数\n",
    "\n",
    "        self.face_encoder = nn.Sequential(\n",
    "            Conv2d(15, 32, kernel_size=(7, 7), stride=1, padding=3),\n",
    "\n",
    "            Conv2d(32, 64, kernel_size=5, stride=(1, 2), padding=1),\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            Conv2d(256, 256, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(256, 256, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            Conv2d(512, 512, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(512, 512, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
    "            Conv2d(512, 512, kernel_size=3, stride=1, padding=0),\n",
    "            Conv2d(512, 512, kernel_size=1, stride=1, padding=0),)\n",
    "\n",
    "        self.audio_encoder = nn.Sequential(\n",
    "            Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            Conv2d(32, 32, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(32, 32, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(32, 64, kernel_size=3, stride=(3, 1), padding=1),\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(64, 128, kernel_size=3, stride=3, padding=1),\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(128, 256, kernel_size=3, stride=(3, 2), padding=1),\n",
    "            Conv2d(256, 256, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(256, 256, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(256, 512, kernel_size=3, stride=1, padding=0),\n",
    "            Conv2d(512, 512, kernel_size=1, stride=1, padding=0),)\n",
    "\n",
    "    def forward(self, audio_sequences, face_sequences): # audio_sequences := (B, dim, T)\n",
    "        \n",
    "        #########################TODO#######################\n",
    "        # 正向传播\n",
    "        face_embedding = self.face_encoder(face_sequences)\n",
    "        audio_embedding = self.audio_encoder(audio_sequences)\n",
    "\n",
    "        audio_embedding = audio_embedding.view(audio_embedding.size(0), -1)\n",
    "        face_embedding = face_embedding.view(face_embedding.size(0), -1)\n",
    "\n",
    "        audio_embedding = F.normalize(audio_embedding, p=2, dim=1)\n",
    "        face_embedding = F.normalize(face_embedding, p=2, dim=1)\n",
    "\n",
    "\n",
    "        return audio_embedding, face_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wav2lip file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "\n",
    "class Wav2Lip(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Wav2Lip, self).__init__()\n",
    "\n",
    "        self.face_encoder_blocks = nn.ModuleList([\n",
    "            nn.Sequential(Conv2d(6, 16, kernel_size=7, stride=1, padding=3)), # 96,96\n",
    "\n",
    "            nn.Sequential(Conv2d(16, 32, kernel_size=3, stride=2, padding=1), # 48,48\n",
    "            Conv2d(32, 32, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(32, 32, kernel_size=3, stride=1, padding=1, residual=True)),\n",
    "\n",
    "            nn.Sequential(Conv2d(32, 64, kernel_size=3, stride=2, padding=1),    # 24,24\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1, residual=True)),\n",
    "\n",
    "            nn.Sequential(Conv2d(64, 128, kernel_size=3, stride=2, padding=1),   # 12,12\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1, residual=True)),\n",
    "\n",
    "            nn.Sequential(Conv2d(128, 256, kernel_size=3, stride=2, padding=1),       # 6,6\n",
    "            Conv2d(256, 256, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(256, 256, kernel_size=3, stride=1, padding=1, residual=True)),\n",
    "\n",
    "            nn.Sequential(Conv2d(256, 512, kernel_size=3, stride=2, padding=1),     # 3,3\n",
    "            Conv2d(512, 512, kernel_size=3, stride=1, padding=1, residual=True),),\n",
    "            \n",
    "            nn.Sequential(Conv2d(512, 512, kernel_size=3, stride=1, padding=0),     # 1, 1\n",
    "            Conv2d(512, 512, kernel_size=1, stride=1, padding=0)),])\n",
    "\n",
    "        self.audio_encoder = nn.Sequential(\n",
    "            Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            Conv2d(32, 32, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(32, 32, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(32, 64, kernel_size=3, stride=(3, 1), padding=1),\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(64, 128, kernel_size=3, stride=3, padding=1),\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(128, 256, kernel_size=3, stride=(3, 2), padding=1),\n",
    "            Conv2d(256, 256, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "\n",
    "            Conv2d(256, 512, kernel_size=3, stride=1, padding=0),\n",
    "            Conv2d(512, 512, kernel_size=1, stride=1, padding=0),)\n",
    "\n",
    "        self.face_decoder_blocks = nn.ModuleList([\n",
    "            nn.Sequential(Conv2d(512, 512, kernel_size=1, stride=1, padding=0),),\n",
    "\n",
    "            nn.Sequential(Conv2dTranspose(1024, 512, kernel_size=3, stride=1, padding=0), # 3,3\n",
    "            Conv2d(512, 512, kernel_size=3, stride=1, padding=1, residual=True),),\n",
    "\n",
    "            nn.Sequential(Conv2dTranspose(1024, 512, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            Conv2d(512, 512, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(512, 512, kernel_size=3, stride=1, padding=1, residual=True),), # 6, 6\n",
    "\n",
    "            nn.Sequential(Conv2dTranspose(768, 384, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            Conv2d(384, 384, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(384, 384, kernel_size=3, stride=1, padding=1, residual=True),), # 12, 12\n",
    "\n",
    "            nn.Sequential(Conv2dTranspose(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            Conv2d(256, 256, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(256, 256, kernel_size=3, stride=1, padding=1, residual=True),), # 24, 24\n",
    "\n",
    "            nn.Sequential(Conv2dTranspose(320, 128, kernel_size=3, stride=2, padding=1, output_padding=1), \n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1, residual=True),), # 48, 48\n",
    "\n",
    "            nn.Sequential(Conv2dTranspose(160, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1, residual=True),\n",
    "            Conv2d(64, 64, kernel_size=3, stride=1, padding=1, residual=True),),]) # 96,96\n",
    "\n",
    "        self.output_block = nn.Sequential(Conv2d(80, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(32, 3, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Sigmoid()) \n",
    "\n",
    "    def forward(self, audio_sequences, face_sequences):\n",
    "        # audio_sequences = (B, T, 1, 80, 16)\n",
    "        B = audio_sequences.size(0)\n",
    "\n",
    "        input_dim_size = len(face_sequences.size())\n",
    "        if input_dim_size > 4:\n",
    "            audio_sequences = torch.cat([audio_sequences[:, i] for i in range(audio_sequences.size(1))], dim=0)\n",
    "            face_sequences = torch.cat([face_sequences[:, :, i] for i in range(face_sequences.size(2))], dim=0)\n",
    "\n",
    "        audio_embedding = self.audio_encoder(audio_sequences) # B, 512, 1, 1\n",
    "\n",
    "        feats = []\n",
    "        x = face_sequences\n",
    "        for f in self.face_encoder_blocks:\n",
    "            x = f(x)\n",
    "            feats.append(x)\n",
    "\n",
    "        x = audio_embedding\n",
    "        for f in self.face_decoder_blocks:\n",
    "            x = f(x)\n",
    "            try:\n",
    "                x = torch.cat((x, feats[-1]), dim=1)\n",
    "            except Exception as e:\n",
    "                print(x.size())\n",
    "                print(feats[-1].size())\n",
    "                raise e\n",
    "            \n",
    "            feats.pop()\n",
    "\n",
    "        x = self.output_block(x)\n",
    "\n",
    "        if input_dim_size > 4:\n",
    "            x = torch.split(x, B, dim=0) # [(B, C, H, W)]\n",
    "            outputs = torch.stack(x, dim=2) # (B, C, T, H, W)\n",
    "\n",
    "        else:\n",
    "            outputs = x\n",
    "            \n",
    "        return outputs\n",
    "\n",
    "class Wav2Lip_disc_qual(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Wav2Lip_disc_qual, self).__init__()\n",
    "\n",
    "        self.face_encoder_blocks = nn.ModuleList([\n",
    "            nn.Sequential(nonorm_Conv2d(3, 32, kernel_size=7, stride=1, padding=3)), # 48,96\n",
    "\n",
    "            nn.Sequential(nonorm_Conv2d(32, 64, kernel_size=5, stride=(1, 2), padding=2), # 48,48\n",
    "            nonorm_Conv2d(64, 64, kernel_size=5, stride=1, padding=2)),\n",
    "\n",
    "            nn.Sequential(nonorm_Conv2d(64, 128, kernel_size=5, stride=2, padding=2),    # 24,24\n",
    "            nonorm_Conv2d(128, 128, kernel_size=5, stride=1, padding=2)),\n",
    "\n",
    "            nn.Sequential(nonorm_Conv2d(128, 256, kernel_size=5, stride=2, padding=2),   # 12,12\n",
    "            nonorm_Conv2d(256, 256, kernel_size=5, stride=1, padding=2)),\n",
    "\n",
    "            nn.Sequential(nonorm_Conv2d(256, 512, kernel_size=3, stride=2, padding=1),       # 6,6\n",
    "            nonorm_Conv2d(512, 512, kernel_size=3, stride=1, padding=1)),\n",
    "\n",
    "            nn.Sequential(nonorm_Conv2d(512, 512, kernel_size=3, stride=2, padding=1),     # 3,3\n",
    "            nonorm_Conv2d(512, 512, kernel_size=3, stride=1, padding=1),),\n",
    "            \n",
    "            nn.Sequential(nonorm_Conv2d(512, 512, kernel_size=3, stride=1, padding=0),     # 1, 1\n",
    "            nonorm_Conv2d(512, 512, kernel_size=1, stride=1, padding=0)),])\n",
    "\n",
    "        self.binary_pred = nn.Sequential(nn.Conv2d(512, 1, kernel_size=1, stride=1, padding=0), nn.Sigmoid())\n",
    "        self.label_noise = .0\n",
    "\n",
    "    def get_lower_half(self, face_sequences):\n",
    "        return face_sequences[:, :, face_sequences.size(2)//2:]\n",
    "\n",
    "    def to_2d(self, face_sequences):\n",
    "        B = face_sequences.size(0)\n",
    "        face_sequences = torch.cat([face_sequences[:, :, i] for i in range(face_sequences.size(2))], dim=0)\n",
    "        return face_sequences\n",
    "\n",
    "    def perceptual_forward(self, false_face_sequences):\n",
    "        false_face_sequences = self.to_2d(false_face_sequences)\n",
    "        false_face_sequences = self.get_lower_half(false_face_sequences)\n",
    "\n",
    "        false_feats = false_face_sequences\n",
    "        for f in self.face_encoder_blocks:\n",
    "            false_feats = f(false_feats)\n",
    "\n",
    "        false_pred_loss = F.binary_cross_entropy(self.binary_pred(false_feats).view(len(false_feats), -1), \n",
    "                                        torch.ones((len(false_feats), 1)).cuda())\n",
    "\n",
    "        return false_pred_loss\n",
    "\n",
    "    def forward(self, face_sequences):\n",
    "        face_sequences = self.to_2d(face_sequences)\n",
    "        face_sequences = self.get_lower_half(face_sequences)\n",
    "\n",
    "        x = face_sequences\n",
    "        for f in self.face_encoder_blocks:\n",
    "            x = f(x)\n",
    "\n",
    "        return self.binary_pred(x).view(len(x), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, join, basename, isfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from models import SyncNet_color as SyncNet\n",
    "import Wav2Lip.audio as audio\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils import data as data_utils\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import os, random, cv2, argparse\n",
    "# from Wav2Lip.hparams import hparams, get_image_list\n",
    "from Wav2Lip.hparams import hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "global_step = 0 #起始的step\n",
    "global_epoch = 0 #起始的epoch\n",
    "device = \"mps\" if torch.backends.mps.is_built() else torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "use_cuda = False\n",
    "syncnet_T = 5 ## 每次选取200ms的视频片段进行训练，视频的fps为25，所以200ms对应的帧数为：25*0.2=5帧\n",
    "syncnet_mel_step_size = 16 # 200ms对应的声音的mel-spectrogram特征的长度为16.\n",
    "data_root=\"../Data_Collection/lrs2_preprocessed/\" #数据集的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list(data_root, split):\n",
    "\tfilelist = []\n",
    "\n",
    "\twith open('../Data_Collection/lrs2_preprocessed/filelists/{}.txt'.format(split)) as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tline = line.strip()\n",
    "\t\t\tif ' ' in line: line = line.split()[0]\n",
    "\t\t\tfilelist.append(os.path.join(data_root, line))\n",
    "\n",
    "\treturn filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, split):\n",
    "        self.all_videos = get_image_list(data_root, split)\n",
    "\n",
    "    def get_frame_id(self, frame):\n",
    "        return int(basename(frame).split('.')[0])\n",
    "\n",
    "    def get_window(self, start_frame):\n",
    "        start_id = self.get_frame_id(start_frame)\n",
    "        vidname = dirname(start_frame)\n",
    "\n",
    "        window_fnames = []\n",
    "        for frame_id in range(start_id, start_id + syncnet_T):\n",
    "            frame = join(vidname, '{}.jpg'.format(frame_id))\n",
    "            if not isfile(frame):\n",
    "                return None\n",
    "            window_fnames.append(frame)\n",
    "        return window_fnames\n",
    "\n",
    "    def crop_audio_window(self, spec, start_frame):\n",
    "        # num_frames = (T x hop_size * fps) / sample_rate\n",
    "        start_frame_num = self.get_frame_id(start_frame)\n",
    "        start_idx = int(80. * (start_frame_num / float(hparams.fps)))\n",
    "\n",
    "        end_idx = start_idx + syncnet_mel_step_size\n",
    "\n",
    "        return spec[start_idx : end_idx, :]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        return: x,mel,y\n",
    "        x: 五张嘴唇图片\n",
    "        mel: 对应的语音的mel spectrogram\n",
    "        t: 同步or不同步\n",
    "        \n",
    "        \"\"\"\n",
    "        while 1:\n",
    "            idx = random.randint(0, len(self.all_videos) - 1)\n",
    "            vidname = self.all_videos[idx]\n",
    "\n",
    "            img_names = list(glob(join(vidname, '*.jpg')))\n",
    "            # print(len(img_names))\n",
    "            if len(img_names) <= 3 * syncnet_T:\n",
    "                continue\n",
    "            img_name = random.choice(img_names)\n",
    "            wrong_img_name = random.choice(img_names)\n",
    "            while wrong_img_name == img_name:\n",
    "                wrong_img_name = random.choice(img_names)\n",
    "            \n",
    "            \n",
    "            #随机决定是产生负样本还是正样本\n",
    "            if random.choice([True, False]):\n",
    "                y = torch.ones(1).float()\n",
    "                chosen = img_name\n",
    "            else:\n",
    "                y = torch.zeros(1).float()\n",
    "                chosen = wrong_img_name\n",
    "\n",
    "            window_fnames = self.get_window(chosen)\n",
    "            if window_fnames is None:\n",
    "                continue\n",
    "\n",
    "            window = []\n",
    "            all_read = True\n",
    "            for fname in window_fnames:\n",
    "                img = cv2.imread(fname)\n",
    "                if img is None:\n",
    "                    all_read = False\n",
    "                    break\n",
    "                try:\n",
    "                    img = cv2.resize(img, (hparams.img_size, hparams.img_size))\n",
    "                except Exception as e:\n",
    "                    all_read = False\n",
    "                    break\n",
    "\n",
    "                window.append(img)\n",
    "\n",
    "            if not all_read: continue\n",
    "\n",
    "            try:\n",
    "                wavpath = join(vidname, \"audio.wav\")\n",
    "                wav = audio.load_wav(wavpath, hparams.sample_rate)\n",
    "\n",
    "                orig_mel = audio.melspectrogram(wav).T\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "            mel = self.crop_audio_window(orig_mel.copy(), img_name)\n",
    "\n",
    "            if (mel.shape[0] != syncnet_mel_step_size):\n",
    "                continue\n",
    "\n",
    "            # H x W x 3 * T\n",
    "            x = np.concatenate(window, axis=2) / 255.\n",
    "            x = x.transpose(2, 0, 1)\n",
    "            x = x[:, x.shape[1]//2:]\n",
    "\n",
    "            x = torch.FloatTensor(x)\n",
    "            mel = torch.FloatTensor(mel.T).unsqueeze(0)\n",
    "\n",
    "            return x, mel, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need update audio.py line 100 for latest librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 48, 96])\n",
      "torch.Size([1, 80, 16])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "ds=Dataset(\"train\")\n",
    "x,mel,t=ds[0]\n",
    "print(x.shape)\n",
    "print(mel.shape)\n",
    "print(t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x31b98c970>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mel[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x31badadf0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOgAAAGgCAYAAACg1SvNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEL0lEQVR4nO2dfYxcV3n/n3vvvK33ZdZex7Pe2Bsv4F8dklDASZwlqFCwsKqoShqrLVKqpik/pYV1iGOpFFckiBZY4A+wgkx4ETJBahrqP0JbUFNFTnEVcEjiAE0acPKDNDZJdv26O/s2M/fl/P5YZ+55vmfn3B2/sIf181mNtGfu27l35sw93/u8eUopRYIgOIm/1B0QBKE1MkAFwWFkgAqCw8gAFQSHkQEqCA4jA1QQHEYGqCA4jAxQQXAYGaCC4DAyQAXBYS7aAN27dy9t2LCBSqUSbdmyhZ566qmLdShBWLZ4F8MX9zvf+Q79+Z//OX31q1+lLVu20J49e2j//v105MgRWrNmjXXbJEnotddeo+7ubvI870J3TRCWHKUUTU1N0cDAAPl+xj1SXQSuv/56NTIy0mzHcawGBgbU6Oho5rbHjh1TRCQveS3717FjxzLHQ44uMI1Ggw4fPky7d+9uvuf7Pm3dupUOHTpkrF+v16lerzfbSruhL/b+6Wsz9YQStswz9sLbuL4B3sXbmnAE0MZts87QdqysfrexK2FJ6O7uzlzngmvQkydPUhzHVKlU2PuVSoXGxsaM9UdHR6lcLjdfg4ODRDT//Vr0y/PSF/559pexN4+/zPVTsvaNf22eVXuvdjf5TXI+p7aMWYyEW/KnuLt376bJycnm69ixY0RE5Hk+eX5Anh8QefyVkM9esfKar4QC9oqVz16J8tiLvBx/KZ+9VKLYSx+8Sin2QhTF7DV/19NfccYL19dfOGMyDm5dbP/RElzhgk9xV69eTUEQ0Pj4OHt/fHyc+vv7jfWLxSIVi8UL3Q1BWBZc8DtooVCgzZs304EDB5rvJUlCBw4coOHh4Qt9OEFY1lzwOygR0a5du+j222+na6+9lq6//nras2cPzczM0B133HExDicIy5aLMkD/9E//lE6cOEH33XcfjY2N0dvf/nZ69NFHjQdHNhL1xoMVIlKoi/iNX/l5rcHX9AL+JNWHdpDjbZWErB025qBjkbbzGLoFB8940Nr2Q10LWQ9tjafZxjVth6yOq5ZN1LhKHi9buSiOCudDtVqlcrlMREH6YSr8UGFmvlQDlPgA9aBb6rd0gGYPmjYHqL5muwPUqW/nhWVycpJ6enqs6yz5U1xBEFojA1QQHOaiaNALQ45UcxoGHjlBgTVLXb3N/3t6V7JlvSv7WLsM3hseCMXpqTOsPTZ2jLWrZ443/4/CWbZM4Zw2e9550biwmtPce3vLLVPejH1d6hpV7qCC4DAyQAXBYZyd4gb5bvLOPhbt7uXT1JVr1rL2ZWvXN/9fXRngyy7jpp1V3WV+oKjBmidPvsbaP3/hJ6z90pH/bv5fneC+xSrm+8Kp3flM17yM6TFOFbOezeuLL7Zzn8198NKewGYjd1BBcBgZoILgMDJABcFhnNWgawc3kh/Md+9Nv3M1W/am37mKtVdXLm/+ny91smWFfIm1Sz4/ZT/kurFY4maYanWatU+dPNH8f3Zmii0LEzCzKPA0As+jLGz6DDWpKfMwML313kQHuovcQQXBYWSACoLDyAAVBIdxVoPe8J4PUL4wrx+vePMmtizfwW2ZtTBVUbMR114Nxd0EGwlXXMlMjbVPnOCaM4z4b9iKztSVMJdfwfc9N8NPAtSddx6BQ2hDNSTnBXXlE1xB7qCC4DAyQAXBYWSACoLDOKtBr9h4DRVL8xqvEXN9dfI06MQ4/Z3JFbguXNHBTzGX4+2p+mnW/vX4SdY+fXKStWdm0iTbcQPsmgoTVcNi4/ewnZQLoJ2NBN22bRdqa9u2mWqz/SQcrfd/Pqm7LwXkDioIDiMDVBAcRgaoIDiMsxr0RLVGhcb870cNwix1uycREXlpCpQg4rowVpClz6uz9qmTXINOTnF9Wwv5/hqa7kwSDMrkqVhIRbydqTmRpMX/Zlvh8gxxd15W0zYLM7GCWFJaoi3kDioIDiMDVBAcRgaoIDiMsxr09GxI+XheP4Yg5ZIEssFTukIQhbAu1zy1mPvenpqYYO0zU1XWnqtCzGeU6qlcvostKxV5u6OYZ230pw2g/DnKs0SLH50DP996jWvlep3304hF9VsLR9/n1zNO+LbYzziGDyRDVrKts2yoRub5rNUt+Y7cKppwTsgdVBAcRgaoIDiMDFBBcBhnNeh0LaHc2VIKcYxlDFrn9sn5XIMSxH96UK5happrt8lJ7nvbmOHre5qm7eziZSb6L1vN2m8aGuJ9UVA2Udn9axOt0tr0LNfGZ7QSFEREp0/9mrWxhMXMDNessZbDNzHcdiGfkbECrg9t/Li0//0MO2i7unE56EwbcgcVBIeRASoIDuPsFHemHlPurKscZrP0YKroe+kKXp5PoSKcNta5maU2x6ewMzPcnKEa3KRQ8lLTSS7H+9HVuYq11637P6yNKUBrde52GMHUXZ+GNkLe79VreImL6iQvcXH8+Ku8Pc7LVExOpGF19Rq/Blg53KjaZvyuZ4S2adNanJGa2UJxfry8p7BZyB1UEBxGBqggOIwMUEFwGGc16FytTkEy//uBEiiA35V8kLqqxR64pYHJIKzPsXYNNGl9ji8PYm62KXR2NP9XUDZiqso1ZbXKty2XeVmJOdC3mBIlilP9pTzujreii7sRdnbzkhcrunv58h5ewvHVV9PK4SfHecnFMOTXIIK2aebC1C9g2tI+ggQ+TOMOIeFoDLmDCoLDyAAVBIeRASoIDuOsBo3CqBlGloCmidGWpqXSjCGsKgQ3wXoNNOgshHHNcpe4XMJ1Yl7TkR6EYU3P8H2fOcPd80qdXAdGCb/8tqQmCfSjATbUYr7Ij7XiMtZeU+EaNcil7TykKp04c4K3T3IbahKBJgWMsDlNs3qe3d3xUrd7InIHFQSHkQEqCA4jA1QQHMZZDRo2QkrUfPfQFxTLv/uaboly3F7oYcmEkGu3GNqG42/EbZ1KS6UZgG3ydJWHqv3ylVdYu+/yK1g7BE/UWdDHQaAtB23t5bimnAX7LloTYxDuPb2pL29HZy9bdgr8eBt1bs+dnuAalSC1qYJ0o0GQpiP14cPD9CnKsLG6o0nPJ2XouYbFyR1UEBxGBqggOIwMUEFwGGc1aByGpGhe46EGNaIRNX2mwHcWqzNEDb68BqUeqMZ9c8njxw60Y+UgXWUYcT114iQvZfjKMa7tulfyFClY0iLUal74Pvi3gqTJQdmJQo7HntYhU6auiUpFvm3/ALepRlBO4/+9+N+sPVfl55mDuNdY+0wS0JweXEN0vM6SfRcz5cmFLFPhsZjYxfdZ7qCC4DAyQAXBYWSACoLDOKtBfSJ6Q50YeWzgZ8XTvFbjBEv+8Y0jqCNRn4M0nTHo3SK/RLrPq+/ZS95PnjrF2j//xRHW3vhWrtV6V/KcRlwZ8n4V83zp9CTPK3TqNLfJnjzJbZeel+rb3jLXnOUevu/Vl/H8RyHYjn/9CthzZ/ixVaJfY8w5hDoP7xmtU6wStacTlzJFp9hBBWEZIgNUEBxGBqggOIy7GtTzmmUCUKZg+QDdTRUlCSqUCHxrI8grhFtgzCf7TQMbnhfwyxmBj+rEqdOsrUBMd5W5BvW1XEsBdAP9gKcmeF6hkye4Dnz11XHWzuVSLT49zfMb1WY7WLvcyzVq/9pB1u4o8eWv/vpl3hfNtzeJuH7Fkoz2qNj5LXTwu8D2l5WEN6uiBeZWstzPzPO4MHpX7qCC4DAyQAXBYZyd4nqUzkjwUTpWfPa1+Z+PNhhw/TPCm9Asg+FOPri9adMe49ctD5cz4Pvq6IYK3F081YgH2/tBOvXsKHGTTDTHp4pzU9zMUj0zwZdXeWqXXC69Lo0ZdH/k/Ygjnqpl4PI1rL1u/VtYO8hxM40uE6arvF9hnfe7UQfXS2NamlGWQveBxA8IZ8tZU16cPhsmIQsotdDVb5FmF7mDCoLDyAAVBIeRASoIDuOuBvU8bd7uGctYW29g1WpMYQKuY16AWsCecqOhaSBfweXLc3NF1ypurlg7xFOedJZ7+JEMr7f0jQBMOKfOcLPJiTGeGnMOKoXnUKuFmgad4/q0UcMQO95esYKfV2UtT/G5es061i4WUx1/5jR3OTx1Ygza3FwUR1AOkjiGCx275bQuQbEwoDnxeYZNg+IiOFiukH43lFIUQdrUVsgdVBAcRgaoIDhMWwN0dHSUrrvuOuru7qY1a9bQLbfcQkeO8AiNWq1GIyMj1NfXR11dXbR9+3YaHx9vsUdBEGy0pUEPHjxIIyMjdN1111EURfR3f/d39IEPfIBeeOEF6uycTwN5zz330Pe//33av38/lctl2rFjB9166630wx/+sK2O6Ro0qzyArjMjSDviG/YmcBXLwSUA7RCDhm0k2vYx16v5FdyuufbyDay9YejNrN3dzcsR5grc1lkspFrPh7SZrx49ytonxl5n7RDK2ucgZUpDd3GE/CkKbMVnwEXRD9DIx7df1beStddU1jf/7+3l7owrOnj6UPysJ0/z80I7qSELPe0zQZt2ht3TDAnLslW29jFF+VrQ7NjtaNC2Buijjz7K2t/61rdozZo1dPjwYfq93/s9mpycpG9+85v00EMP0fve9z4iItq3bx9deeWV9OSTT9INN9zQzuEE4ZLnvDTo5NknhatWzf8qHj58mMIwpK1btzbX2bRpEw0ODtKhQ4cW3Ee9XqdqtcpegiDMc84DNEkS2rlzJ91444109dVXExHR2NgYFQoF6u3tZetWKhUaAzPAG4yOjlK5XG6+1q9fv+B6gnApcs520JGREXr++efpiSeeOK8O7N69m3bt2tVsV6vVzEGK5Qh17YAl1jGNI0GYlqEy0G6a47bNhpYSJQaN0w36amA9D8taezm3D+by4Ivr8WPltXC2OSgr8er//i9rz07x5cU8lGGE1JlxkmpQz7f7t0YNrklPneC2TIzISyBtTFmz9+Yhbq6/n3/WHVBG8dgrXJePjXPtXa9PsbbStLqfa/09WahtalT7ck+3U8OzDB9KkBS01KYqSYg/IWjNOQ3QHTt20Pe+9z36r//6L1q3Lv3S9ff3U6PRoImJCXYXHR8fp/7+/gX3VSwWmSFbEISUtqa4SinasWMHPfLII/T444/T0NAQW75582bK5/N04MCB5ntHjhyho0eP0vDw8IXpsSBcQrR1Bx0ZGaGHHnqI/uVf/oW6u7uburJcLlNHRweVy2X60Ic+RLt27aJVq1ZRT08P3XXXXTQ8PCxPcAXhHGhrgD7wwANERPTe976Xvb9v3z76i7/4CyIi+tKXvkS+79P27dupXq/Ttm3b6Ctf+UrbHVNKNTUCas4EbJ0epfP9PGiBMIJ4UIwnRAdNn+vABDRrQ9M4BSiZ0NnL7X+lbu5rS6BLFNgPc+j6qdkqq6d5Cs/pyTN8XUwlAlovDFH1pDpRJfya6H6jREQxaMoISh2ePsX7kofSD57uswzn3NPF1125ssL3FfC+5CDW9LXXf8Xas7OpzTaJLLGiZJad8AwRykF/6Lzme50rYCwv37cep4zlSGy0NUAXk9uzVCrR3r17ae/eve3sWhCEBRBfXEFwGBmgguAwzsaD+oHfzDWUgB9qDD6woZ5sBqfhoK8SWOyDnRPtngqMfKHm/Fkq8LjInlW8nGCpk+cgmq3zFJ85SJLjl3xYnh6rgb61YMEFyUN18FmNE15WMcinxwpy/DwuW8PPo1DkO5+e4t5eqEGnJnhfu0rpM4Mc5F2aiHi/Zib5eZU7ua/uW950JWvnIQb3V6/8T/N/tJGiXTTIQfpW+Kzz8F0oQV6oDt08CM8yIvjeNbT42wypy/u0+FUFQfhNIwNUEBzG3SmuT+T7C88F0OxS16aOUcjNKhhmhWaVfIlP7+aK3P0OzS7KTy9ZHkKlusq9fFMwEdTBZQ4ftxdzfHlO+/1s1Lhpw8cpLvzUhnAdsBBboZT2rQhTt77VfIpbqfCUJqfPgMmnyvvmET/v3u50e8zAfmaSV+eOGnx6HM7Bvlbxaz44uJG1KUhlw8uvvMj3FfF958E0kgc7F07HS+DxFmhmsxhMfxGY9/QwSGWk4WmN3EEFwWFkgAqCw8gAFQSHcVaDBl7QrOCVAxer2OPz/ZpmdkENGnloduHN0gpuCpnr4u556CqYy6eatXcl12rFEtdHjRBMPBG49oGFB6t/R5pGbdS5OQJPJEmgUrjHl+ehUnh5Vbn5P6YhuXwdD4tbA5q0VuN9KYC5qbujzNorSmk7hGuiYm6ymZ3h7foMT7tZh+reQ2/mfb18XVqGYnqWa86Tp3j6lETB9cYMKfCMoOGhzkzbMXxP6lA1L9LcDtupti13UEFwGBmgguAwMkAFwWGc1aCFfJ6Cs25cObCHonU01rRE2OAaBTUpZoxEO2gBXMuiaa5jiqXUTrpyFbcP5iBdR6PBRU0AuRhRi0RQKrGhLY+wTCKUY0A9pUCjdnRAGYrL1zb/HxjgaUcG1nJdVwMtNwWlDsvdXMP29fLyhFGYXvT6HLg3Er9mccQ/oJlZbmNtgAZd2cePvWpN2l4HNlJ4BEBnzhxnbXzekCT2z8fTdD4+A0B31EjT3qJBBWGZIANUEBxGBqggOIy7GrRQapZC8DA1CKQ18TR/2xqksZgB26KRltPDdIk8pYaf5+t3dqU2vU4IJ8PfO7M8O2/GUGIhUnx7j1qn+MR0KQn4uCZgBy11ch/jSn+qQTEdaHdXL2v/8iWeVqQ6wcO41l3O04t2d/Sx9snjqS1zrsbtgx7YuBVcg1oDdDn4sY6Nc7/gFeX0M6ms5eUeI9CUDUiJMj09wdeHUDgsA6KXqkT/WgWfFytJIhpUEJYHMkAFwWFkgAqCwzirQUulAuUK8zYyH5wiC3muEwNN3PmoYcCONj3NfTtzqAvRXzbH7XR9mu0z5/F+xGD3zMpskWA6Fvi5bGh2uXrMtVsN4w1hXx6m74CYTz0diwc6fGqaX7OXX/41awc+P++hDW9h7cYMv4Yv/eJVfWu2bEUP35dhe0RtB88Ujp+aYO3uk2nq0zf1QumNAV7+cbbG93Xs2C9Ze2aCX/PYVr/QSLWDq2rbLl6Cyh1UEFxGBqggOIwMUEFwGIc1aAfli/P+o2j3RJuT/isTgW0xX+AaJwTb1wSU9VMTPB5x1eXcT3V1X1qaoFTitsVZ8AM2SlTAeWDaR2Vo0FQDzTa4HgoxHhTPu8iDTbt7elm7s6tbW5f76Z46McHak1WewnPj0JtYu6ub7/v1M7w8Ya2WXpeeMi+PgfbbMEZ7L2tSAp99DNpvrpEuPz3BtXR3mftZXzHEU3gWIJ736NGXWPv0qdd43+b0zwTrdkBwKVvWehEid1BBcBgZoILgMDJABcFhnNWggZej4Kx9rgB2Ny+AUhCF1CYYgo7o7eL2wrkZrkvmTk/wfRX59hs2cL3VrWk3LG+Xh3jPGuipBHRjBMlqPbD3ztVT7TbX4H6haB8kiJnFnLxv2JTfINbKaUyAby3Ge14Bds4eKLN4Eq7h+AmuQVd0pVq9q8z9l09PjLF2rcE/H9Sohr0R7NTd5dQPON/RzZYlYO8tdnLtvX4DlMCAqvAzM9zvd2oijSc9Mf4qW3bi16+wdsTKPyoi4s8UWiF3UEFwGBmgguAwzk5xi4Ui5c+Gm2HKfQ8fzWslFUoleEzfDa5isO1qmK7lIFxt3QB3F1tRSqdoDTBtKCMlBv/9SyBtiWEuivn6uskoApMNugni9LgEqVvmatwE9LOfPad1hE+HV5Z5ms2+y3gKE8xkOnaCl2+ozvEpck9fGqLnwzdueo6btWJCl0UwRSn++XR08mns6ko6LV11GU9JY1hC4FhJzK9RvoNLq0IH/x52acfWwxCJiFas4Nf/f3/58/S4KqFkDiueL4zcQQXBYWSACoLDyAAVBIdxVoMGnt9MUxmALsSgn5wmbAIwXQRQPrATSj3kurl26ICUJx0d3J2PV/sGfQT98qEmoCI8D7s+1lO9YBkCXBcvClYGx1QiZ06n2s9TUBaii6csycM1mZ7mrn/TUBoxgZSgXiHt3EyNm3SmZydYOwYdqEDnE4Qa6pqTiKhvTZrKpbOb69MQngGEEYSTQfWMOOSmLQXhhTnNJNfdaw8uDLR8r3Ec0S+fe8K6/hvIHVQQHEYGqCA4jAxQQXAYZzWoShSps+kvkhg0DdgXdd0ZgKHNB/3qgw70wa6GdemjOtctuqTF0oZmmk1wvwNdSD5oTr6UPO0d1KCErn6GRuWgNi9pIWYlKB/Y1cW1G3rXzcxybYb2YMrz85wN0zQzk1PcXa7W4HpWRVyDogtj10pe6mEthAN26s8U4BkAps1MIOVnEvFr1IBLXA8h1E139QQbdq7An3VU+tPUplHUoF8+R4tC7qCC4DAyQAXBYWSACoLDuKtBVap94hA1KK6daocc2D1zEHYVenZ/WCzzVyfwz9TEXgQaMjY0KSpB1JzKspSI5W5EzQmhbKi3UHPWa9zIV9LKLq6GMoqd4Mc7NcXtnFiOAcv6oW6cnplo/l+dPcOWqQDPi29bBB/XyweHWHsN2EFVkJ53CM8usJ8xtHE5ZFGlGnwPQ+2aKkiD6mM0oHZeUWS3mbLtFr2mIAi/cWSACoLDyAAVBIdxVoN65JP3xu8HZr3AcgBJa/9Y9MUtFlBHQDk8kAcRpDVRevrLAsR7+qh5QO/CvnKwvu+jMVPXoCCIQIN6Oa45Uf5OnuHpRQur09jGIqTdRO08M8tjF7GqgQf6twH+tDON1A4aelyrFTp5jGXSwftSWcvjcd/0Fl7WvgvSiYZa3GwIZSTAxE0hlJGo1aHUYcivMcr+UBOtUQ0/H9Ckmt9vDHrVhtxBBcFhZIAKgsPIABUEh3FWg5IiTXty8WDaQVuD/q8FiG1UOdCYEZQuxxT+mpDxQOOAm69BjAGHsO+8h37CWjyo4eeLJdf5eaK+ws0TraZCDOdRhzIT07PcXzbI868N+rjW5iBFKKV9yZUgppIg/rbE/YDfsul3WLv/8nWsnevgZRUb2nljGXo0JUdY6hCeETQaYBNHjaotr9chthTShwZRek0S/B5YkDuoIDiMDFBBcBgZoILgMM5qUE955L2hk8BpEkvQJbq9CnQF/gI1MBctlASshWC/wiSw2g4V2ibR/zLgYjkBfeuBryja6SItNjIC2yIR2t34xiFoohWdPD5x5Wot9y3YUKfA7tmA3D1JDKUQFZZZ5Fe91NWTHgqeCXRCzuPVqyus3buG+9p6kJPI8K/V/1eoMfk1a0Csb4x2T2iHWAJSazegNEdch5jZmTQXE+ZHtiF3UEFwGBmgguAwzk5xddD1zJjiam3DDTBjWzQxIFhdK9IekeMUF49NOTg2loqA7UPoil7ewUizCSYEBaFQCsxJ3WUetqVX9sKpYAzHyhX51wTTV/pQBtuHVCJ5La1MAZZ1QnqVLizFUeJmlNCwlbSeLqL5ZxamnXNgDmrMcRkRNrDcBn530s8ggmk/Tnlntap6Sqa4grA8kAEqCA4jA1QQHMZdDaoUeWe1UaaO1LRdDDFBcYLuXva0JEYbNaimeZQH+4Y2ph1BGYnnUa9xbRJpJQNDTG1paC/QfXl+7FV9PF1lLp+G4WFqkAT8AgMwRaG5woPK1T787uuZYQpFril1EwwRUbGDp1vBYxslBI00M+n/qEHNMEV4BgAueEaJR3Q5ZceFMEYw10WN1i6INuQOKggOIwNUEBzmvAbo5z73OfI8j3bu3Nl8r1ar0cjICPX19VFXVxdt376dxsfHz7efgnBJcs4a9Omnn6avfe1r9La3vY29f88999D3v/992r9/P5XLZdqxYwfdeuut9MMf/rCt/Xue1yzrnqUL9TbqJ5vNlIgoQs0KbQX+e5HmTOZhqBqEgCWQtxFTeqI9LIJyd6FW1g/7hTF3GIG3ooe79q1azTVooKUpQUUUKzwvOHQAYXEgtQOjzGJ6rDy49hUhxUm+xJejBvXh2GjGjrVrmmRoPQ9vT2hbRt9N1LvU2v6OGjTRfBLNdKytOac76PT0NN122230jW98g1auTA3Lk5OT9M1vfpO++MUv0vve9z7avHkz7du3j370ox/Rk08+eS6HEoRLmnMaoCMjI3TTTTfR1q1b2fuHDx+mMAzZ+5s2baLBwUE6dOjQgvuq1+tUrVbZSxCEedqe4j788MP07LPP0tNPP20sGxsbo0KhQL29vez9SqVCY2NjC+5vdHSUPvWpT7XbDUG4JGhrgB47dozuvvtueuyxx6gEPpLnyu7du2nXrl3NdrVapfXr15Pve800lOgriugaFOf3ph3UrjkNzYppM1SqLVD3QeVDijB8SXFd4uG+oS91rcRCCHZPBaFsAYixvgov59Db18vaM3opiBqcM9k1qA8pT7DsBKak0X1zCx0r2LJCCTRo0a5Bceeo/WLtmqJtMiG7xjSfbaBfN5YfTD+TKEK7J6RAifR+XSQ76OHDh+n48eP0zne+k3K5HOVyOTp48CDdf//9lMvlqFKpUKPRoImJCbbd+Pg49ff3L7jPYrFIPT097CUIwjxt3UHf//7303PP8cqjd9xxB23atIn+9m//ltavX0/5fJ4OHDhA27dvJyKiI0eO0NGjR2l4ePjC9VoQLhHaGqDd3d109dVXs/c6Ozupr6+v+f6HPvQh2rVrF61atYp6enrorrvuouHhYbrhhhsuXK8F4RLhgvvifulLXyLf92n79u1Ur9dp27Zt9JWvfKXt/SilmnrSTJ+I2i3VBjH4rMag3WL0OzXiR3E5atZ0f6hBFbyDpSCMeFG078LiUNM1DdA06NdbXMGfCVQGuKQodXLtNxumKTgaoJ880LdeAr61kCIFSz9gqtN8IdWVHZB6pbSC+96iry7aPTGdKH7e+ueFzw+w5IL53QCNis8nYH3d1tmo81hS1KBK37YNDXreA/QHP/gBa5dKJdq7dy/t3bv3fHctCJc84osrCA4jA1QQHMbZeNAkSZr6EOMPjZhPrY12zwg0irEvS2zp/PqgLbTcMx66aoK0gGoMFMfc1xbLOSiIRww1OyjaSP0Czzm0cvAK1u5ZyXP7YD4ePa9QA3yCgwIv2eiBVkYNmoDmxDSeJc3W2bGCa+EilG4IcN9G/C74RoMu1P2d8ZoZ3w3UpJhjCu2exvOIdHur5pzf2cL/ZyB3UEFwGBmgguAwMkAFwWHc1aBx3NSWEWgz1JV6vlks7Ya5aNGuafhyxqhTMKZTiwcFLRGgtMhxe6Khd0OubxVoIl1+FcFeiKUc1m/YwNqoE6dmZlh7ppZqJrQFF0Df5groDwt2UB/y4ua5hi1qMZ4l3DeUiTB8o1EHwjUPYf1GmJ4X6lPUlOi37Wflp8LPT/u8zGMtXmfakDuoIDiMDFBBcBhnp7j1sEHJ2XSOjQaYOiyhPfoUh2iB9IcRPkrHtJoNazvWKnnhr5vhIgfL8fG64baGj+q1OW4npKfEmNtCiZsv9CksEVEdzRHa1BBLO2DKEx9ymuRgmqrAzBIUoWp2RzrFzcN0GWbH7JyJzCkupqjBz1d3j8TpsvFdQDmEroHG9ljdTEv32uD7ohhtcBnl11sgd1BBcBgZoILgMDJABcFh3NWg9RolZ33lwgbqSNACkf5o3a45UcMY7lzGY358XK6nV+FLfNAZeUjXEWC6DjjWHGgcvWeFIqQGKfDUIDGU544h5acR4KTpRg/67UM+SqyKHeS4GQVdAwuQDkcvOeijMs8q1QH5VrAEhlEGRPu80fRhpFyF5RjSF0IIWa0G5Qq10hwqQj9PfALBCkXQYpE7qCA4jAxQQXAYGaCC4DDOatAobBCdtYOirgwNW6Wt/KBdh5ilIlADoXpL9QOWo8NUHzksBY+pQqCUALol6meN2+byqEGhm6h3weAYaC52Rr+hnGCAy8GVD1NlYtvXju1haksM4YrQlY/3O0rwGUPrtCUhfm/ADlqHELyaVmpjvj0Lbb5+pIcD4vU3reTa/6JBBWFZIANUEBxGBqggOIyzGrQRhZR481ozzvCh5ClPQHMapRswhSeUisASdEZJunR9tBei7kNtF6CvrsfthRjO1NB8YAPQkDmwgyaQX8WDNqav1MPRDI2JJezhvHJgB83nue8t2n+ZrRnTjhD6QoMGhcwhWMLRSHmi6fgI7Mr1OteYjQwNWp/j7bAOdmr98zLqXcB3g320hpd2S+QOKggOIwNUEBxGBqggOIyzGjRs1Emd1VFGOQejZGDrdP+GXdOwi2KaC1gOJeisEZ+oQzIIgtbpKYmIcljPkG3LdR/aD7G+e5ADnajFZQawLqb+MLxKM3x30T6sx3iiry3aBKMI08LwtcMEvwutyzlg/CZqTowzDo02aM4Y/W3Tfz387NEOzbyhDaNpS+QOKggOIwNUEBxGBqggOIyzGjSKQlJnfUINf03DtpnO6dGWaJYTzCg/iPoAgz41bYEl0xHMd4QSBvPx5DB+VPPlxfPw4LcVbZke5BEKQM96mm40Y2IhHSXadz17esoEdKReHtK4vnANUaOGlrSn8+u3zknUgLSm6HuLGtVmX1+gq0xpG7qbAHbNxBdXEJYFMkAFwWFkgAqCw7irQeOIlD+vCbJS9utttIMa+siIB7Wvj+gurqhBzVKGUDIQdKICLZfzuY+rXhYB+02J3e7mB5A3KMC8rOmxQ4yprEM5QrBzFrqhTD38zuMVTDR9huuiTRDz4qKd03geEYOO1HRnCJozAk0aGqUl4VjQt4Ra+3WbNlK+bZDXnl0ojxLe7ZbIHVQQHEYGqCA4jLNT3DiOiPz5qRZOe5TXesprTn/tU1pzypvxCJwdC1JdYqWtBlQ/y6FpxO4aGMf6+tgvTI3JP0rDfITVt7RrmGA1aMBDV76MMDsFJgd9imtcXmNKC58PprBR6OoHaWK0aWwDprA4XcYUMzFO9cGtEKfX/BqDGQw+Wn1d/E7akDuoIDiMDFBBcBgZoILgMM5q0CgKSdG8aQCz6OP8nmtQ+2N7w+ySoUmxerRuZzHdBkEPGV6DkAoETB9oSfE83UWOg1YTBfrK88FdD00hvq6JcF3Uxnad6MWY4oRvnWiug0b4X0ZqTDM8EDSpUX5QKwOCrnyYHgVLQ2SUlcCUoSyRpofpbPj1Nswwi0TuoILgMDJABcFhZIAKgsM4q0HjJElFWWZmkdZ2UCztYISIZaxvpK9kq9v3hbrkfDCss0YoG+gjtBfi5pbwp0ChwOXNBug+yuHXiG8fa88BsBxk3LDrQgw/izPKgMRaG9c17aB2vYspV1GD6rc3I+MJXRjkDioIDiMDVBAcRgaoIDiMuxo0jom8eQ2Arp8YtqVjptGENm5gpPPAsCzAlrnCkhJjwb5ktPVUjpn7guVGGF1k09qwLx/LXfCvCYZl+RGk4YSyi6w0R2jXnBj6ligs+4G2TR5SFoe6BoW0mdDGnJ4KNSjaLj20kWvrorncsKHqqXKk9IMgLAtkgAqCw8gAFQSHcVaDJkncLFWHvqGYZl9vmylO0DEUj4SxjnZdyPQaCA/D79fH5bAn334s3RcUzxnjVjE21YxzbR33ahw34NorD5IJyy94kEokBxdZLxUfZWjQCP1hFWpUriNDOHaslWtIwBfXaIOdVMGxCc4Tb2fMLuqhxke7tH4gWjRyBxUEh5EBKggOIwNUEBzGWQ2qlGrGdirwhzVSUMJ2vG3XYuiba9s3EaT7N1xx8feuPbsn9s1MUdkaLJFgHBvP01IuA62uWPohCriWM3Q7aFC9b1GEdk3UpOgfi/GikCoTSgRGWgnBLM2ZlaMINahhv9Q/L3xWYfuss/JeacgdVBAcRgaoIDiMDFBBcBhnNWiikuYc3ygpmBgGqXRZls4z9Ja9XCHCbK5GyTlMKoT9tGsPLGHHfHEzYkvxUJk+yboGNa4B3xnGZKLtEsFrrPvihoYOxPhP0IWwPpatx7auSbGEPepbSjDek2NYwC1vGN8bfJ6glYNUKqtwpbbdItcTBGEJkAEqCA7j7BRXqYhUM/UGlFho4zG1UaGqzepnplshn6rY9pVVKa0dl6+sKS5WL7NNM+cP3boUgVE2AlKg5HLtmab0Y5tpTqFf0E+jIlkd2jCNjbX1Iww3izGlCe9nVhCYoVC0HWSoF1ZNXZGZgqbldotcTxCEJUAGqCA4TNsD9NVXX6U/+7M/o76+Puro6KBrrrmGnnnmmeZypRTdd999tHbtWuro6KCtW7fSSy+9dEE7LQiXCm1p0DNnztCNN95Iv//7v0///u//Tpdddhm99NJLtHLlyuY6X/jCF+j++++nBx98kIaGhujee++lbdu20QsvvEClUsmyd868q9/CE3tMh6hjKwtBtJC+srsCBpACRVlzntjJcu0zQ+H0MDq7SSBElzgs4wdmF27C4V+DAFLK+AFvhw0wlfiQAgU+BL3yuOHql+Xa1+ApTRo1qJpt0aRYTtDQoDF89mg+wmuIqTV1DYpfPLiGujnJ9v1F2hqgn//852n9+vW0b9++5ntDQ0PagRXt2bOHPvGJT9DNN99MRETf/va3qVKp0He/+1364Ac/2M7hBOGSp60p7r/+67/StddeS3/8x39Ma9asoXe84x30jW98o7n85ZdfprGxMdq6dWvzvXK5TFu2bKFDhw4tuM96vU7VapW9BEGYp60B+qtf/YoeeOAB2rhxI/3Hf/wHffjDH6aPfvSj9OCDDxIR0djYGBERVSoVtl2lUmkuQ0ZHR6lcLjdf69evP5fzEIRlSVtT3CRJ6Nprr6XPfvazRET0jne8g55//nn66le/Srfffvs5dWD37t20a9euZrtarZ4dpIre0HiGY5TNYGWEfMGmRrl2ju/Z9ZevGbQw/Seui7ZJW7rQhfrGS1rwJWgLNlJsYDpR6Juuh3FbPyt0ygjRw16jXVVLu2mkzQQ9C7bLBmhMtIvi+rrWQxtr22lSM9rMDgqLsr5ni6WtO+jatWvprW99K3vvyiuvpKNHjxIRUX9/PxERjY+Ps3XGx8eby5BisUg9PT3sJQjCPG0N0BtvvJGOHDnC3nvxxRfpiiuuIKL5B0b9/f104MCB5vJqtUo//vGPaXh4+AJ0VxAuLdqa4t5zzz30rne9iz772c/Sn/zJn9BTTz1FX//61+nrX/86Ec3f1nfu3Emf/vSnaePGjU0zy8DAAN1yyy0Xo/+CsKxpa4Bed9119Mgjj9Du3bvp7//+72loaIj27NlDt912W3Odj33sYzQzM0N33nknTUxM0Lvf/W569NFH27KBEs3rmDe0DIZh4YyfzfczysChjc4DP1PUDjYdiZoy8Pm6+XweOgPHpsVj2ISz/HyNY4EmsqXdBPugcf1h3pUVaqVrQdScYcOuKdEOathNDf9am18w6nQUoXie+F1pfc1Rl2OpQvZoQy1ek3oq06P7N0u1WqVyuUwD199Ffq5IRAs9PLHlybVL/XbqoRC1N0BzUCezWCzyrlzAAYoOFxG4X2M6YMzhq2+P+wrIfg2gSOoCCX9bD9BGOMeW4UMg8yHRLLT59gnmKNIGMOYcwvhPfLqFjgsK40VxqGjb47r4oE1frlRMavZ/aHJyMvOZi/jiCoLDyAAVBIdxOB400fQE2PR8u27ky1rb/xZqG7oyaH0sww7axrYLYVMbmVNzIyXk4mNTjX5hSQuc2cU4pcUYW/QDTnUi+vEa8ZxgJzVK3BupMPHYWrmMTKVnt+9mYlFW5r7OzYdb7qCC4DAyQAXBYWSACoLDOKtByaPWdoh27BPGpnZDaWZ6S6veXXyZRCIypYjFQmT4DKOJx5CgoAMNu5xev91SKo9MPWWYIyyak4go0cwdGKMZo100svvqGnZPzGmk+wFnlAHBcpFGbiXDB5mjfwLm1wLMWqJBBWH5IQNUEBxGBqggOIyzGtT3vTT2UmXY+LQ5fZbfLgosc33sB/8Na8cOmqVnDZdFWJqo1udl2HfhvALUv4b/LNsZHJfruhh9c9GVL+bHxhy8iVZ+MLEsIyKKQ9ScsH6W762tHAOCtydMOtSOFyzGfxq5gkWDCsKyQwaoIDiMs1NcHTOjoe13Bd0CbXM7Mn6iMGTMNo3Ncu0zeobToDZmUIarH1Yky6yovfhUj4YM8KCMBKazTNDMAtPWpHXKSaPfmRXSYXss1WGZPprujhnhZYRuotiXlns6L1Mg69KF2Y0gCBcDGaCC4DAyQAXBYX4rNGjWfJ6XMWidJpNogZJzmJ6yjRCyLL2KZJXps4WUYZkIs4RFa90338ZyhBkmCHYsNHVkVMk2UmmmbbP0A+rZDH1rhLpBJWvt48R0opnlIY2MChnV1ttYps7NyiJ3UEFwGRmgguAwMkAFwWGc1aDW8oMeaoP0d8Yzavi1Fz6W7Z7XetfZpeTtGsjQTElrt7Usu6jhrpfgci0jneEuRy3Xnd8XaExD76JGTdtmOBmmPAE7Z5YuxGvO+p2RqtT4fp17OUkzhSc0tWcj7aRWkTuoIDiMDFBBcBgZoILgMM5q0FjFTdueWbaAr8t+ZYzs7VmlC9vVIa11Icoj1LPtalJbeYYsH1W0H2JqEJZZHvUt+seifsXUl7hvQ//qWdXxGtjbZm1DQyDzpqYFbaUaiMz0rRiTh886zL5pm2Zcs3NF7qCC4DAyQAXBYWSACoLDOKtBoyQm/6zWwbL0hmpki8GXFmMbMX0K7stIk4H6N20bZeeNcENMg5GRBrKNWMYE7J5RCPZE1KRoy1StNSgZJewxPWWW/yymJdHiQTM0P+rGrMykNkzTJFRty4gVNpKW4Odny4t6gZA7qCA4jAxQQXAYGaCC4DDOalC9/KCZdRM1aetgu6wK2ihUTM2DGlSvqmysDLtuXXYe9zV/7MWXWMdtQyjbZ+b+4ei2SqNfHtpYM3xxY0zTiRpUS7tp2Ezt5RhQF/qmkytv6ylYDT9r3HV7vrmmPtbTogLG94w3FitZ5Q4qCA4jA1QQHMbZKS6rbpYxVdGbZggXpsSwP6jH9c2CZOkb5hTJuusFQsQwy33r3aGboGHKMNJw2qfPelhe1vTZSKOJKU6MlCet3QzN82hdIZvInFYaLnXECZhJzv6BGK6XMaYmzXDfs6TdND5L9kWSKa4gLAtkgAqCw8gAFQSHcVaDel6q/wzNaflZyQoBU0YlrwxNamg5CzYRSQtoVgxnMo6dvhOB5jRSRJI95MvQ5rouNLQxph1BbZahdy2hb6ZpyX4ehi0rQ7zZUtYYJjdcnrG+cWjtDaOCuWHeY/W4W/YRkTuoIDiMDFBBcBgZoILgMM5qUJUoUmcrN6PVyA8s7nrKbjNFMtWAkQpTs4Oim+B5hxy1tuGiHooVaFJcnlEigdk+0TUvQR0IzQj0FVSmxurerF+opeFYHtomYX2zhCPvS6hV6DbKgEBfDPsvrIDnZbj+aeFqhvspamet3+18TeQOKggOIwNUEBxGBqggOIyzGtQnv5nqxCgJiCFgbH6/+LSZROenG037oX1nhv02w/6op6uMjDJ8qBPtpeEXsrJqK8OijLJ7GBKWESLGjmVo49ahaQvtyywpiH3Xw83Ar9dHG7i9VIcXZ6RktWU8sbzRqqTJQsgdVBAcRgaoIDiMDFBBcBh3Nag//yIiM32l5WfF8NvNMnRibsaMNCVc/tp9O7NSZhjJLm1a0LBNYiwj2g/BvmiYjvXULfYSf4ZPqqFB7fpX9+U1YzAz7LWGLy5+XjZfXdSv8Nkax7bHphrfDe1/MzWO5bshGlQQlgcyQAXBYWSACoLDOKtBPc9L/S4N/0tc17Ynuy0L5RS+YaRubPH/wke2pwA1Yk1tWjCrbB/aLo3zaK3dsjSooRsNWWgvdahrPdPOmaExDdtj1vott1zA7mzXv+15zdpzJ7FDiQYVhOWBDFBBcBgZoILgMM5qUI5dlzC7HApSH+IkM7QaHspDP2CrERZ2laGnssrUK1suH7Dh+fbTWMAVVy38Py3CLpqxvqmXNf/YjHILRh5ifP5gLamAi2w2bCLje2Rsj2ufe1l7/TTFF1cQlgkyQAXBYZyd4iqltKkAmifwkban/U8tl83v1149GsHQNt3kYJgugMxqZhhChuUctGMZpg4saUEBX26YcCx9wTArNNEYMgBMJRl905fjtDNrxmqkSfXtxi3bUg+vP6yM3ys8lBnq1jrVjumSqP+/+Kmy3EEFwWFkgAqCw7Q1QOM4pnvvvZeGhoaoo6OD3vzmN9M//MM/sFu9Uoruu+8+Wrt2LXV0dNDWrVvppZdeuuAdF4RLgbY06Oc//3l64IEH6MEHH6SrrrqKnnnmGbrjjjuoXC7TRz/6USIi+sIXvkD3338/PfjggzQ0NET33nsvbdu2jV544QUqlUrn1suMR/N609AwWSX/jNKGvG2UK7yAcw5Dk1rME6hBDdOI4cqHB2vtvpelb40yEkaVbHTta53G0zNMFXadjroP++rj/izpbzJLG6JJxzAftf4eZoXFBUFOW2RehVa0NUB/9KMf0c0330w33XQTERFt2LCB/umf/omeeuqpswdWtGfPHvrEJz5BN998MxERffvb36ZKpULf/e536YMf/GA7hxOES5627gfvete76MCBA/Tiiy8SEdHPfvYzeuKJJ+gP/uAPiIjo5ZdfprGxMdq6dWtzm3K5TFu2bKFDhw4tuM96vU7VapW9BEGYp6076Mc//nGqVqu0adMmCoKA4jimz3zmM3TbbbcREdHY2BgREVUqFbZdpVJpLkNGR0fpU5/61Ln0XRCWPW0N0H/+53+mf/zHf6SHHnqIrrrqKvrpT39KO3fupIGBAbr99tvPqQO7d++mXbt2NdvVapXWr1/P1kF5ZdjpNOlgaFC08RnpUzCdP2hSLAegaxxDkoAdDfaFsjDAcgFQaoCHo6EGBd2He49Rc7ZOS2KGh2XYOWNMARry5RaXRaOEfZZtOMJSEXBels/HcCM0fPnQng7fFUspjvnd6+GAlvAyIko0XW6E3Floa4D+zd/8DX384x9vaslrrrmGXnnlFRodHaXbb7+d+vv7iYhofHyc1q5d29xufHyc3v72ty+4z2KxSMVisZ1uCMIlQ1sadHZ21kgiHQRB88na0NAQ9ff304EDB5rLq9Uq/fjHP6bh4eEL0F1BuLRo6w76h3/4h/SZz3yGBgcH6aqrrqKf/OQn9MUvfpH+8i//kojmpxc7d+6kT3/607Rx48ammWVgYIBuueWWi9F/QVjWtDVAv/zlL9O9995LH/nIR+j48eM0MDBAf/VXf0X33Xdfc52PfexjNDMzQ3feeSdNTEzQu9/9bnr00UfP3QZKC6QwzMylqW+LugHXsKdLNI/NlsK+0CZndAbfgFZr+2Ni2Bax/CB8lEbakta2SvQBjrPsnFmpQoy0JnrYXEbpBsu2ZzfgbZRzlu+G6febFaOHWOzxWala2MEXH27mqXaC034DVKtVKpfLtOa6/0t+rkBECzgPwDRbX97O4D27hXXfZlt/SJRhCAcBgctjeAASRg3WjvRBFMKDGBiwQeYAhQGuPdiJE77vGB8CZdR9wfPAHw/9xwGdA7IGKO7bTCLFsX3+6PxuBDtk1JjBejjMaSIrzlULZlAqJqq/SJOTk9TT09Oyv0TiiysITiMDVBAcxtl4UI/SyacxpSX0n9VSamSE5RmaE2P+0DYGbTbJyfClzXk8RjOrdJ5ZvlBbnhF7GsOU1/jlNXKV6tcM952VGhPthYuPBzUNhHYfVsNuiiUFCdBXhymrEUecEYtqlCOE/fk2X1yAxaIq7Elr5A4qCA4jA1QQHEYGqCA4jLsaVCv9gBrUXLe1BkVdERu6DwD/WHzybjODGnmA4PfPjHU0ChC2PJjhExzwN+IIzDAorm361tCUoLXQPos+q1nnobXRBJOVstNDHUgZaNsbGjKjZojxDCCjDCO7phkmGsV8uCUnkSAsC2SACoLDyAAVBIf57dCgxjJj7Zb7MaWYvay5oZ8s7ppZJe8zc9pk+rS2diUzbZdZbdB+ukudEZ+IGglLw2e0DbdCbbmhQe2+tniNjTsK2rH1a477RoxctnYbremDbNnW0Lt+63UtyB1UEBxGBqggOIyzU1yf0l8Po1yAbUPDbmJP82iWisDNW5s+zGpYOMW1R4HgFMwWEmZMBY3H+hnpLA33PT0EzD5FxVC3OGwdrTK/a4xA0c4jxmPxto8mHsPNE8DrwCJnjFg03Br6Yi+XQZ7lGmdFs+gz3DaqpMkdVBAcRgaoIDiMDFBBcBhnNahuZmkvR0JGxL3p22dtm6tbSzozUJthesoI2kb6Sk1Xmu5h6DaYEW5mcalDHYhZDBLI9GC4FaI+jlu72KH+Qs0ZGKkw+b7RrRDLR3qW8zJc9YymXUeaDx3Uwv8vsK0XaKGHigg+rpbIHVQQHEYGqCA4jAxQQXAYZzVo4Cnyz87rsQSgkblNm/8b3lpZKTTaTr1oIctVDFNlglYLDI2j/X4GcA0gLC4m1K+YXgVsmXpWv5BrzCTGNrru8bZRikOhztT+B62GkYRmKkzQx5it0ChxoWvQjM8jM6El6n4sC6KFkOGxUFv7Be246HjZGrmDCoLDyAAVBIeRASoIDuOsBlUqNSVla4V0uVkiDvVRRmqKjGN5lhLreGzM2I6l9GK0gxq+o7r90F5eEO2JqHdjsGWGjVq6Lto5oV+mXTMrzWZr+6ORopMAZffzxfSiaAe1hehltrPASgG8J9ZNdTu1pDwRhGWCDFBBcBgZoILgMM5qUM+zVpLj6DrEsD3aSwL6oEMwVeMCB9P2jdtCbGPGz59hOTNsfHqJQNR94KMKOhFtlbrmJCKKwrq2LmhOI11lRglAw+fYEgeLaTUNOzWmZkEbbEaaGLYs8422sJaZQF9c+PKKBhWEZYgMUEFwGBmgguAwzmpQ3/OaPriZeYOYbRIXZfjaZvhr2qpLR7HdRhfkePlBI/cP2kGxwrbWNnQdKlhcjn3TNOf8sbR2Yo+5NPI4GfbExVfYpjgj3hNTfKL/clbMJuyNN42S55ZtTYxyGpaSI+g7zezrbRxX7qCC4DAyQAXBYWSACoLDOKtBKY6amsGsYm+rMZihKTF+MMJ4Q7svqG6PNHMOgRaL0BaGmpO38di6RkVdiJInjLid08zxyo/lJfq+M8ovZMTUGqUjMOGOfl6oVzNyLWXbDM3sxAv/3+62lF3LUo8HxZhlP8CVM/qyMHIHFQSHkQEqCA7j7BS3UZ8j/43pJ7rnYTkAZmaBkC8sWxDB8gYsT+ypQ1hImVHRCtNX8uVRxE0dhnnDg7ZexgBNHWA+ChNuojGnxGC+0I8FU2tjSosyIaukheE6qO8fpr9oeuJLsyepxgp6jQV7mQ9jWmp80cBUAmYaVuUcv5MwxQ20tJtKJRTDV6EVcgcVBIeRASoIDiMDVBAcxlkNOjczS34wr2U8eGKNaThtcV1GmBbqKSylhy5zni2kzB76ZLj2gVnFSEFpmIj0KtiYKoTvG0smoBbHtsfKD9rTgeI1M0o/oJnFKJWotbGEn4f9suvGBFNfQpulhskwkxgupMb68L0KeNvP5dNVA/4l9aGdz6frqiSh2SlaFHIHFQSHkQEqCA4jA1QQHMZZDVqfmyXPn5+3oxRAO6jS7FWoI9COGaDOyEglYqb0j1suw7SblKA9EFwDDT2GKUD1Y9nDzQIIb0KthiUwlKVMn6F3UZeDBjVc/cyYPv3A1nWN9KIZGLuzVYc0YsJ42zckKH7xwLaptf0cH0rYzjENiterNXIHFQSHkQEqCA7j3BT3jSmpGUmvrQO/K8oSwYBTJoVzIJzOZVRlVpYprplhHaM6YGoDU1x0W9P7kjXFNU7LmKrjeVmqd2dljs+Yptrb7W3bdh4+S7aCrKoBZqU7PG+UT62voRlNZH6W2RUTHBygU1PzBqLZ1x5f4p4Iv52ELZdkRa4ZyhDfgF0vtoRgK6ampqhcLlvX8dRihvFvkCRJ6LXXXiOlFA0ODtKxY8eop6dnqbv1W0G1WqX169fLNWuDpbhmSimampqigYEB44En4twd1Pd9WrduHVWrVSIi6unpkS9bm8g1a5/f9DXLunO+gTwkEgSHkQEqCA7j7AAtFov0yU9+korF4lJ35bcGuWbt4/o1c+4hkSAIKc7eQQVBkAEqCE4jA1QQHEYGqCA4jAxQQXAYZwfo3r17acOGDVQqlWjLli301FNPLXWXnGF0dJSuu+466u7upjVr1tAtt9xCR44cYevUajUaGRmhvr4+6urqou3bt9P4+PgS9dgtPve5z5HnebRz587me65eLycH6He+8x3atWsXffKTn6Rnn32Wfvd3f5e2bdtGx48fX+quOcHBgwdpZGSEnnzySXrssccoDEP6wAc+QDMzM8117rnnHvq3f/s32r9/Px08eJBee+01uvXWW5ew127w9NNP09e+9jV629vext539nopB7n++uvVyMhIsx3HsRoYGFCjo6NL2Ct3OX78uCIidfDgQaWUUhMTEyqfz6v9+/c31/n5z3+uiEgdOnRoqbq55ExNTamNGzeqxx57TL3nPe9Rd999t1LK7evl3B200WjQ4cOHaevWrc33fN+nrVu30qFDh5awZ+4yOTlJRESrVq0iIqLDhw9TGIbsGm7atIkGBwcv6Ws4MjJCN910E7suRG5fL+eiWU6ePElxHFOlUmHvVyoV+sUvfrFEvXKXJElo586ddOONN9LVV19NRERjY2NUKBSot7eXrVupVGhsbGwJern0PPzww/Tss8/S008/bSxz+Xo5N0CF9hgZGaHnn3+ennjiiaXuirMcO3aM7r77bnrssceoVCotdXfawrkp7urVqykIAuMJ2vj4OPX39y9Rr9xkx44d9L3vfY/+8z//k9atW9d8v7+/nxqNBk1MTLD1L9VrePjwYTp+/Di9853vpFwuR7lcjg4ePEj3338/5XI5qlQqzl4v5wZooVCgzZs304EDB5rvJUlCBw4coOHh4SXsmTsopWjHjh30yCOP0OOPP05DQ0Ns+ebNmymfz7NreOTIETp69OgleQ3f//7303PPPUc//elPm69rr72Wbrvttub/zl6vJX1E1YKHH35YFYtF9a1vfUu98MIL6s4771S9vb1qbGxsqbvmBB/+8IdVuVxWP/jBD9Trr7/efM3OzjbX+eu//ms1ODioHn/8cfXMM8+o4eFhNTw8vIS9dgv9Ka5S7l4vJweoUkp9+ctfVoODg6pQKKjrr79ePfnkk0vdJWeg+WR3xmvfvn3Ndebm5tRHPvIRtXLlSrVixQr1R3/0R+r1119fuk47Bg5QV6+XxIMKgsM4p0EFQUiRASoIDiMDVBAcRgaoIDiMDFBBcBgZoILgMDJABcFhZIAKgsPIABUEh5EBKggOIwNUEBzm/wO2HhNzY4jZwgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[:3,:,:].transpose(0,2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#损失函数的定义\n",
    "logloss = nn.BCELoss() # 交叉熵损失\n",
    "def cosine_loss(a, v, y):#余弦相似度损失\n",
    "    \"\"\"\n",
    "    a: audio_encoder的输出\n",
    "    v: video face_encoder的输出\n",
    "    y: 是否同步的真实值\n",
    "    \"\"\"\n",
    "    d = nn.functional.cosine_similarity(a, v)\n",
    "    loss = logloss(d.unsqueeze(1), y)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, model, train_data_loader, test_data_loader, optimizer,\n",
    "          checkpoint_dir=None, checkpoint_interval=None, nepochs=None):\n",
    "\n",
    "    global global_step, global_epoch\n",
    "    resumed_step = global_step\n",
    "    \n",
    "    while global_epoch < nepochs:\n",
    "        running_loss = 0.\n",
    "        prog_bar = tqdm(enumerate(train_data_loader))\n",
    "        for step, (x, mel, y) in prog_bar:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #####TODO###########\n",
    "            ####################\n",
    "            #补全模型的训练\n",
    "            x = x.to(device)\n",
    "\n",
    "            mel = mel.to(device)\n",
    "\n",
    "            a, v = model(mel, x)\n",
    "            y = y.to(device)\n",
    "\n",
    "            loss = cosine_loss(a, v, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            \n",
    "\n",
    "            global_step += 1\n",
    "            cur_session_steps = global_step - resumed_step\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if global_step == 1 or global_step % checkpoint_interval == 0:\n",
    "                save_checkpoint(\n",
    "                    model, optimizer, global_step, checkpoint_dir, global_epoch)\n",
    "\n",
    "            if global_step % hparams.syncnet_eval_interval == 0:\n",
    "                with torch.no_grad():\n",
    "                    eval_model(test_data_loader, global_step, device, model, checkpoint_dir)\n",
    "\n",
    "            prog_bar.set_description('Epoch: {} Loss: {}'.format(global_epoch, running_loss / (step + 1)))\n",
    "\n",
    "        global_epoch += 1\n",
    "\n",
    "def eval_model(test_data_loader, global_step, device, model, checkpoint_dir):\n",
    "    #在测试集上进行评估\n",
    "    eval_steps = 1400\n",
    "    print('Evaluating for {} steps'.format(eval_steps))\n",
    "    losses = []\n",
    "    while 1:\n",
    "        for step, (x, mel, y) in enumerate(test_data_loader):\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            # Transform data to CUDA device\n",
    "            x = x.to(device)\n",
    "\n",
    "            mel = mel.to(device)\n",
    "\n",
    "            a, v = model(mel, x)\n",
    "            y = y.to(device)\n",
    "\n",
    "            loss = cosine_loss(a, v, y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if step > eval_steps: break\n",
    "\n",
    "        averaged_loss = sum(losses) / len(losses)\n",
    "        print(averaged_loss)\n",
    "\n",
    "        return\n",
    "\n",
    "latest_checkpoint_path = ''\n",
    "def save_checkpoint(model, optimizer, step, checkpoint_dir, epoch):\n",
    "    #保存训练的结果 checkpoint\n",
    "    global latest_checkpoint_path\n",
    "    \n",
    "    checkpoint_path = join(\n",
    "        checkpoint_dir, \"checkpoint_step{:09d}.pth\".format(global_step))\n",
    "    optimizer_state = optimizer.state_dict() if hparams.save_optimizer_state else None\n",
    "    torch.save({\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer_state,\n",
    "        \"global_step\": step,\n",
    "        \"global_epoch\": epoch,\n",
    "    }, checkpoint_path)\n",
    "    latest_checkpoint_path = checkpoint_path\n",
    "    print(\"Saved checkpoint:\", checkpoint_path)\n",
    "\n",
    "def _load(checkpoint_path):\n",
    "    if use_cuda:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path,\n",
    "                                map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "def load_checkpoint(path, model, optimizer, reset_optimizer=False):\n",
    "    #读取指定checkpoint的保存信息\n",
    "    global global_step\n",
    "    global global_epoch\n",
    "\n",
    "    print(\"Load checkpoint from: {}\".format(path))\n",
    "    checkpoint = _load(path)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    if not reset_optimizer:\n",
    "        optimizer_state = checkpoint[\"optimizer\"]\n",
    "        if optimizer_state is not None:\n",
    "            print(\"Load optimizer state from {}\".format(path))\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    global_step = checkpoint[\"global_step\"]\n",
    "    global_epoch = checkpoint[\"global_epoch\"]\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total trainable params 16435072\n",
      "Load checkpoint from: checkpoints/expert_checkpoints/checkpoint_step000080000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pm/x83zrlkn551fhsmr72ncx8yw0000gn/T/ipykernel_79811/3162096508.py:93: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam([p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad],\n\u001b[1;32m     29\u001b[0m                        lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m train(device, model, train_data_loader, test_data_loader, optimizer,\n\u001b[1;32m     35\u001b[0m       checkpoint_dir\u001b[38;5;241m=\u001b[39mcheckpoint_dir,\n\u001b[1;32m     36\u001b[0m       checkpoint_interval\u001b[38;5;241m=\u001b[39mhparams\u001b[38;5;241m.\u001b[39msyncnet_checkpoint_interval,\n\u001b[1;32m     37\u001b[0m       nepochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m27\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 105\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[0;34m(path, model, optimizer, reset_optimizer)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m global_epoch\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad checkpoint from: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path))\n\u001b[0;32m--> 105\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reset_optimizer:\n",
      "Cell \u001b[0;32mIn[20], line 93\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load\u001b[39m(checkpoint_path):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device:\n\u001b[0;32m---> 93\u001b[0m         checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m         checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path,\n\u001b[1;32m     96\u001b[0m                                 map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m storage, loc: storage)\n",
      "File \u001b[0;32m~/anaconda3/envs/wav2lip/lib/python3.9/site-packages/torch/serialization.py:1097\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1105\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/wav2lip/lib/python3.9/site-packages/torch/serialization.py:1525\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# Needed for tensors where storage device and rebuild tensor device are\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1525\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location\n\u001b[1;32m   1528\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/anaconda3/envs/wav2lip/lib/python3.9/site-packages/torch/serialization.py:1492\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1491\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1492\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/anaconda3/envs/wav2lip/lib/python3.9/site-packages/torch/serialization.py:1466\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1466\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1467\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1468\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1471\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/anaconda3/envs/wav2lip/lib/python3.9/site-packages/torch/serialization.py:414\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 414\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/wav2lip/lib/python3.9/site-packages/torch/serialization.py:391\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    389\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m--> 391\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/wav2lip/lib/python3.9/site-packages/torch/serialization.py:364\u001b[0m, in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    362\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    365\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    366\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    367\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    368\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    370\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "checkpoint_dir = \"checkpoints/expert_checkpoints/\" #指定存储 checkpoint的位置\n",
    "checkpoint_path = 'checkpoints/expert_checkpoints/checkpoint_step000080000.pth'\n",
    "# 指定加载checkpoint的路径，第一次训练时不需要，后续如果想从某个checkpoint恢复训练，可指定。\n",
    "\n",
    "if not os.path.exists(checkpoint_dir): os.mkdir(checkpoint_dir)\n",
    "\n",
    "# Dataset and Dataloader setup\n",
    "train_dataset = Dataset('train')\n",
    "test_dataset = Dataset('val')\n",
    "\n",
    "############TODO#########\n",
    "#####Train Dataloader and Test Dataloader \n",
    "#### 具体的bacthsize等参数，参考 hparams.py文件\n",
    "train_data_loader = data_utils.DataLoader(\n",
    "    train_dataset, batch_size=hparams.batch_size, shuffle=True,\n",
    "    num_workers=hparams.num_workers)\n",
    "\n",
    "test_data_loader = data_utils.DataLoader(\n",
    "    test_dataset, batch_size=hparams.batch_size,\n",
    "    num_workers=8)\n",
    "\n",
    "# Model\n",
    "#####定义 SynNet模型，并加载到指定的device上\n",
    "model = SyncNet_color().to(device)\n",
    "print('total trainable params {}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "####定义优化器，使用adam，lr参考hparams.py文件\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad],\n",
    "                       lr=1e-5)\n",
    "\n",
    "if checkpoint_path is not None:\n",
    "    load_checkpoint(checkpoint_path, model, optimizer, reset_optimizer=True)\n",
    "\n",
    "train(device, model, train_data_loader, test_data_loader, optimizer,\n",
    "      checkpoint_dir=checkpoint_dir,\n",
    "      checkpoint_interval=hparams.syncnet_checkpoint_interval,\n",
    "      nepochs=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wav2lip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
